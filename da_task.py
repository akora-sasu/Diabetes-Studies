# -*- coding: utf-8 -*-
"""DA Task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/188zvkk2BNPHd3uYgM7ixY2vYc6L5aEqY

#**DA Home Task from Webeet**
 Exploratory Data Analysis (EDA) and ML perfomrmed in this code aims to figure out what risk factors are most predictive of diabetes in the United States.

##Importing Libraries and Loading Database
"""

#Importing the needed libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.inspection import partial_dependence
from sklearn.inspection import PartialDependenceDisplay
# Load the dataset
df = pd.read_csv('/content/diabetes_BRFSS2015_felix - diabetes_binary_5050split_health_indicators_BRFSS2015.csv')

"""##EDAs"""

# Display the first 5 rows
df.head()

# Display basic information
print(df.info())

"""
Remarks:
*   There are no missing values in the data
*   Data type conforms with observation of elements in the data displayed
"""

# Display descriptive statistics
print(df.describe())

# Plot the target variable distribution
##this confirms that the target variable is split 50-50 between diabetic and non-diabetic
sns.countplot(x='Diabetes_binary', data=df)
plt.title('Distribution of Diabetes_binary')
plt.show()

# Correlation matrix
 ## visualizing the correlation matrix using a heatmap to understand relationships between features
correlation_matrix = df.corr()

# Heatmap
plt.figure(figsize=(18, 15))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix Heatmap')
plt.show()

"""Remarks:
*  order of importance, High BP, High Chol, BMI, GenHlth, Age, DiffWalk, PhyHlth, HeartDiseaseorAttack have positive relationships with diabetes; they could be strong predictors
*  income corr. with education positvely
*   other variables such as age corr with High BP which may be which might suggest multicollinearity (watch out during linear regression)
"""

# Plot histograms for all features
##Ploting the distribution of each feature variable, differentiating by the target variable (Diabetes_binary).
df.hist(bins=20, figsize=(20, 15))
plt.show()

"""Remarks:
*   most of the respondents have high blood pressure incedence
*   a little much more of the respondents have high cholestrol level

*   majority of the resp. have had their chol. level checked
*   BMI-body mass index of the resp.is skewed right

*   a little more of the resp. are non-smokers
*   a few of the respondents had stroke, and heart disease incidence

*   most of the resp. have undertaken physical activities in the past 30 days
*   most of the resp. consume less achohol in a week
*   most of the resp. have health coverage(including health insurance)
*   very few of the resp. could not access doctor services because of cost
*   on a scale of 1 to 5, most resp. were in a good health condition
*   most respondents have not experience days of poor mental and physical health
*   most resp. do not have difficulty in walking and climbing stairs
*   there is more females than male resp.
*   majority of respondents age ranges from 50-74
*   most of resp. have graduated from college or technical course
*   mjority of resp had income >= $50,000

"""

## Principal Component Analysis
# Standardize the data
features = df.drop('Diabetes_binary', axis=1)
features_scaled = StandardScaler().fit_transform(features)

# PCA
pca = PCA(n_components=2)
components = pca.fit_transform(features_scaled)

# Plot the PCA results
plt.scatter(components[:, 0], components[:, 1], c=df['Diabetes_binary'], cmap='coolwarm')
plt.title('PCA of Features')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

"""Remarks:

*   the overlapping clusters suggest less clear separation, indicating that more complex models or additional features might be needed.

##Modeling the determinants of diabetes
The overlap observed in our PCA suggest a limited linear separability of our cohorts(diabetic or not). using a linear model  (such as Logistic Regression) might struggle to accurately classify the data. As such, a more complex model that can capture non-linear relationships or interactions between features are typically better suited.


*   Random Forest which is an ensemble of decision trees that mitigates the overfitting problem of a single tree by averaging predictions from multiple trees is used.
This is because it is robust to overfitting, handles non-linear data, works well with categorical and numerical features.

*  cons: Less interpretable than a single decision tree, can be computationally intensive.
"""

# Spliting data into Test and Train data setts
df_train, df_test = train_test_split(df,
                                     test_size=0.2,
                                     random_state=42, #this is just to keep the random value fixed so that anytime we run it is mentained in the rnp
                                     shuffle=True # default it is set True, just wanted to emphasize it should schuffle. if its time series shuffle is false
                                     )
print("df_train shape: ", df_train.shape)
print("df_test shape: ", df_test.shape)
df_train.head(2)

# getting X and Y variables
X = df.drop('Diabetes_binary', axis=1)  # Features
y = df['Diabetes_binary']  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y)

"""Remarks:
*   Features (X): These are the attributes used to make predictions (e.g., age, weight, blood pressure).
*   Target (y): This is what we are trying to predict (whether the person has diabetes or not).
*   Train-Test Split: The data is split into a training set (used to train the model) and a test set (used to evaluate its performance).
* 80% of the data is used for training, and 20% for testing.
* Training Set: Used to train the model.
* Testing Set: Used to evaluate how well the model generalizes to unseen data.
"""

#Train the Random Forest Model
# Initialize the Random Forest classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Fit the model to the training data
rf_model.fit(X_train, y_train)

"""Remarks:

* The Random Forest algorithm is applied to the training data. This step involves creating multiple decision trees (the "forest") where each tree is trained on a random subset of the data. The results from all trees are then aggregated to make the final prediction.
* n_estimators: This parameter controls the number of trees in the forest. More trees generally improve performance but increase computation time.
* random_state: This ensures that the model is reproducible (i.e., you get the same results each time you run the code).
"""

#Make Prediction on the Test Set

y_pred = rf_model.predict(X_test)

"""Remarks:

* Predictions (y_pred): These are the model’s predicted outcomes for the test set. Each prediction corresponds to a row in the test set, where the model predicts whether the person has diabetes (1) or not (0).
* At this step, we don't interpret results yet, but rather prepare to assess how well the model did.
"""

#Evaluate the Model- the model is evaluated using metrics like accuracy, confusion matrix, and classification report:
# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)

# Classification Report
class_report = classification_report(y_test, y_pred)
df.print("Classification Report:\n", class_report)

"""Remarks:

Accuracy: This metric tells you the percentage of correct predictions out of all predictions made. It is calculated as (True Positives + True Negatives) / Total Observations.
* A high accuracy indicates that the model is good at predicting the target variable.
* However, accuracy alone can be misleading, especially in imbalanced datasets, which is not the case here since the dataset is balanced.

Confusion Matrix: This matrix shows the number of true positives, true negatives, false positives, and false negatives.
* True Positives (TP): The number of instances where the model correctly predicted diabetes.
* True Negatives (TN): The number of instances where the model correctly predicted no diabetes.
* False Positives (FP): The number of instances where the model incorrectly predicted diabetes.
* False Negatives (FN): The number of instances where the model incorrectly predicted no diabetes.
The confusion matrix is useful to assess where the model is making errors (e.g., is it predicting too many false positives or false negatives?).

Classification Report: This report includes precision, recall, and F1-score for each class (0 and 1 in this case).
* Precision: The percentage of true positive predictions among all positive predictions.
* Recall (Sensitivity): The percentage of true positives among all actual positives.
* F1-Score: The harmonic mean of precision and recall, providing a balance between the two.
This report helps you understand the model's performance on each class individually.
"""

# Get feature importances
importances = rf_model.feature_importances_

# Create a DataFrame for visualization
feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)

# Plot feature importances
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importances)
plt.title('Feature Importances')
plt.show()

"""Remarks:

Feature Importances: This bar plot shows which features are most important for the model’s predictions.
* Higher Importance: Features with higher importance scores contribute more to the decision-making process of the model.
* Lower Importance: Features with lower importance scores contribute less, and in some cases, may be considered for removal if they add noise.

This step is crucial for understanding what factors the model is using to make predictions. It can provide insights into what drives diabetes risk, according to the data.

Overall, BMI is the most important diabetic risk factor among others.
"""

pip install matplotlib scikit-learn

print(df.columns)


#pdp for age
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 7))
PartialDependenceDisplay.from_estimator(rf_model, X_train, features=['BMI','Age','GenHlth','Income','HighBP'],kind='average', ax=ax)
plt.show()

#pdp for age
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 7))
PartialDependenceDisplay.from_estimator(rf_model, X_train, features=['PhysHlth','Education','MentHlth','HighChol','Fruits'],kind='average', ax=ax)
plt.show()

